{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>pyentimento: Toolkit para multitarefas para an√°lise de sentimentos e SocialNLP<h1/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scientist Jr.: Karina Gon√ßalves Soares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link de estudo:\n",
    "\n",
    "* [Github: pysentimiento](https://github.com/pysentimiento/pysentimiento)\n",
    "\n",
    "* [pysentimiento: A Python Toolkit for Sentiment\n",
    "Analysis and SocialNLP tasks](https://arxiv.org/pdf/2106.09462.pdf)\n",
    "\n",
    "* [More Scraped Data, Greater Bias](https://www.deeplearning.ai/the-batch/research-shows-that-training-on-larger-datasets-can-increase-social-bias/?utm_campaign=The%20Batch&utm_content=267121221&utm_medium=social&utm_source=facebook&hss_channel=fbp-1027125564106325)\n",
    "\n",
    "\n",
    "* [ON HATE SCALING LAWS FOR DATA-SWAMPS](https://arxiv.org/pdf/2306.13141.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Neste Notebook estudamos a `biblioteca pysentimiento`, um `Toolkit Multilingual` para extra√ß√£o de opini√µes e an√°lises de Sentimentos `(centrado no Idioma Espanhol)`.\n",
    "\n",
    "`pysentimiento` √© uma biblioteca que utiliza modelos pr√©-treinado de transformers para diferentes tarefas de SocialNLP.Usa como modelos bases a BETO: Spanish BERT e RoBERTuito em Espanhol, BERTweet em Ingl√™s e outros modelos similares em Italiano e Portugu√™s.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pysentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos `criar um analisador`. O `create_analyzer` recebe a tarefa e o idioma como par√¢metros.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karinag/karina_python/git-hub/pysentimiento/venv_pysent/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pysentimiento import create_analyzer\n",
    "\n",
    "import transformers\n",
    "\n",
    "transformers.logging.set_verbosity(transformers.logging.ERROR)\n",
    "\n",
    "analyzer = create_analyzer(task=\"sentiment\", lang=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Vejamos alguns exemplos:`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<font color=\"red\">Exemplo1</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=POS, probas={POS: 0.972, NEU: 0.021, NEG: 0.007})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exemplo1 = analyzer.predict(\"O Ronaldinho √© muito bom como jogador!\")\n",
    "\n",
    "exemplo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√≥tulo: POS\n",
      "Probabilidade Positiva: 97.22%\n",
      "Probabilidade Neutra: 0.020972739905118942%\n",
      "Probabilidade Negativa: 0.006807348690927029%\n"
     ]
    }
   ],
   "source": [
    "# Obtendo a nossa sa√≠da 'exemplo1', de maneira mais expl√≠cita: \n",
    "output_label = exemplo1.output  # Obtemos o r√≥tulo (POS, NEU, NEG)\n",
    "probabilities = exemplo1.probas  # Obtemos as probabilidades associadas\n",
    "\n",
    "# Probabilidades individuais para cada r√≥tulo:\n",
    "positive_probability = probabilities.get(\"POS\", 0.0)\n",
    "neutral_probability = probabilities.get(\"NEU\", 0.0)\n",
    "negative_probability = probabilities.get(\"NEG\", 0.0)\n",
    "\n",
    "# Ter√≠amos o seguinte:\n",
    "print(f\"R√≥tulo: {output_label}\")\n",
    "print(f\"Probabilidade Positiva: {round(positive_probability, 4)*100}%\")\n",
    "print(f\"Probabilidade Neutra: {neutral_probability}%\")\n",
    "print(f\"Probabilidade Negativa: {negative_probability}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<font color=\"red\">Exemplo 2</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=NEG, probas={NEG: 0.938, NEU: 0.057, POS: 0.005})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.predict(\"A tinta da minha caneta acabou, nossa!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<font color=\"red\">Exemplo 3</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=NEU, probas={NEU: 0.931, NEG: 0.049, POS: 0.021})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.predict(\"Que dia √© hoje?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<font color=\"red\">Exemplo 4</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=NEG, probas={NEG: 0.955, NEU: 0.026, POS: 0.019})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.predict(\"Hoje Eu estou üò≠\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"yellow\">Predi√ß√£o em batch</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se temos um conjunto de ora√ß√µes, `pysentimiento` faz a predi√ß√£o em conjunto e de maneira eficiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|‚ñã         | 1/15 [00:00<00:01,  8.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.53 s, sys: 5.92 ms, total: 2.54 s\n",
      "Wall time: 1.38 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "oraciones = [\n",
    "    \"Amo ser Cientista de Dados\",\n",
    "    \"Ver tanta pobreza me d√° tristeza.\",\n",
    "    \"O Sol est√° muito distante\",    \n",
    "] * 5\n",
    "\n",
    "for sent in tqdm(oraciones):\n",
    "    analyzer.predict(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:00<00:00, 18.99 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.95 s, sys: 647 ms, total: 4.59 s\n",
      "Wall time: 6.43 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[AnalyzerOutput(output=POS, probas={POS: 0.989, NEU: 0.009, NEG: 0.002}),\n",
       " AnalyzerOutput(output=NEG, probas={NEG: 0.987, NEU: 0.007, POS: 0.006}),\n",
       " AnalyzerOutput(output=NEU, probas={NEU: 0.847, NEG: 0.139, POS: 0.014}),\n",
       " AnalyzerOutput(output=POS, probas={POS: 0.989, NEU: 0.009, NEG: 0.002}),\n",
       " AnalyzerOutput(output=NEG, probas={NEG: 0.987, NEU: 0.007, POS: 0.006}),\n",
       " AnalyzerOutput(output=NEU, probas={NEU: 0.847, NEG: 0.139, POS: 0.014}),\n",
       " AnalyzerOutput(output=POS, probas={POS: 0.989, NEU: 0.009, NEG: 0.002}),\n",
       " AnalyzerOutput(output=NEG, probas={NEG: 0.987, NEU: 0.007, POS: 0.006}),\n",
       " AnalyzerOutput(output=NEU, probas={NEU: 0.847, NEG: 0.139, POS: 0.014}),\n",
       " AnalyzerOutput(output=POS, probas={POS: 0.989, NEU: 0.009, NEG: 0.002}),\n",
       " AnalyzerOutput(output=NEG, probas={NEG: 0.987, NEU: 0.007, POS: 0.006}),\n",
       " AnalyzerOutput(output=NEU, probas={NEU: 0.847, NEG: 0.139, POS: 0.014}),\n",
       " AnalyzerOutput(output=POS, probas={POS: 0.989, NEU: 0.009, NEG: 0.002}),\n",
       " AnalyzerOutput(output=NEG, probas={NEG: 0.987, NEU: 0.007, POS: 0.006}),\n",
       " AnalyzerOutput(output=NEU, probas={NEU: 0.847, NEG: 0.139, POS: 0.014})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rets = analyzer.predict(oraciones)\n",
    "\n",
    "rets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"yellow\">Emojis</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suporta, tamb√©m, o uso de `emojis` atrav√©s da Biblioteca [emoji](https://pypi.org/project/emoji/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=NEG, probas={NEG: 0.976, NEU: 0.016, POS: 0.008})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.predict(\"ü§¢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=POS, probas={POS: 0.925, NEU: 0.069, NEG: 0.006})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.predict(\":)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Hashtags, tamb√©m:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=NEG, probas={NEG: 0.992, POS: 0.004, NEU: 0.004})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.predict(\"#Isto√©UmaMerda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"yellow\">An√°lise Emocional</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pysentimiento` fornece an√°lise Emocional por meio de modelos pr√©-treinados com conjuntos de dados [EmoEvent](https://github.com/fmplaza/EmoEvent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos o Objeto:\n",
    "emotion_analyzer = create_analyzer(task=\"emotion\", lang=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=['fear'], probas={admiration: 0.013, amusement: 0.002, anger: 0.009, annoyance: 0.013, approval: 0.006, caring: 0.005, confusion: 0.004, curiosity: 0.003, desire: 0.004, disappointment: 0.028, disapproval: 0.012, disgust: 0.160, embarrassment: 0.016, excitement: 0.002, fear: 0.890, gratitude: 0.005, grief: 0.008, joy: 0.001, love: 0.007, nervousness: 0.049, optimism: 0.006, pride: 0.002, realization: 0.005, relief: 0.001, remorse: 0.001, sadness: 0.074, surprise: 0.003, neutral: 0.009})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_1 = emotion_analyzer.predict(\"Eu machuquei meu joelho jogando bola, isso √© terr√≠vel!\")\n",
    "\n",
    "emotion_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fear']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A Emo√ß√£o √©:\n",
    "emotion_1.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admiration': 0.013477839529514313,\n",
       " 'amusement': 0.0018875550013035536,\n",
       " 'anger': 0.009365188889205456,\n",
       " 'annoyance': 0.013239799067378044,\n",
       " 'approval': 0.00569023285061121,\n",
       " 'caring': 0.005219749640673399,\n",
       " 'confusion': 0.004016146529465914,\n",
       " 'curiosity': 0.0025675150100141764,\n",
       " 'desire': 0.004219981841742992,\n",
       " 'disappointment': 0.028135400265455246,\n",
       " 'disapproval': 0.011510009877383709,\n",
       " 'disgust': 0.16009768843650818,\n",
       " 'embarrassment': 0.01590888574719429,\n",
       " 'excitement': 0.001899012946523726,\n",
       " 'fear': 0.8895401954650879,\n",
       " 'gratitude': 0.005402678158134222,\n",
       " 'grief': 0.008150695823132992,\n",
       " 'joy': 0.0013532412704080343,\n",
       " 'love': 0.006999167148023844,\n",
       " 'nervousness': 0.04916279762983322,\n",
       " 'optimism': 0.006161699071526527,\n",
       " 'pride': 0.0018651897553354502,\n",
       " 'realization': 0.005212029907852411,\n",
       " 'relief': 0.000912616727873683,\n",
       " 'remorse': 0.0012565108481794596,\n",
       " 'sadness': 0.0744243785738945,\n",
       " 'surprise': 0.0028698265086859465,\n",
       " 'neutral': 0.008908512070775032}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temos v√°rias Emo√ß√µes e s√≥ uma tem uma alta probabildiade:\n",
    "emotion_1.probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Emo√ß√£o da nossa senten√ßa √©: fear com uma probabilidade de: 0.8895401954650879\n"
     ]
    }
   ],
   "source": [
    "name_of_emotion = max(emotion_1.probas, key=emotion_1.probas.get)\n",
    "\n",
    "value_of_emotion = emotion_1.probas[name_of_emotion]\n",
    "\n",
    "print(f\"A Emo√ß√£o da nossa senten√ßa √©: {name_of_emotion} com uma probabilidade de: {value_of_emotion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=['surprise'], probas={admiration: 0.012, amusement: 0.007, anger: 0.005, annoyance: 0.010, approval: 0.002, caring: 0.001, confusion: 0.003, curiosity: 0.011, desire: 0.003, disappointment: 0.004, disapproval: 0.002, disgust: 0.001, embarrassment: 0.005, excitement: 0.143, fear: 0.002, gratitude: 0.003, grief: 0.002, joy: 0.006, love: 0.003, nervousness: 0.001, optimism: 0.002, pride: 0.002, realization: 0.031, relief: 0.003, remorse: 0.001, sadness: 0.002, surprise: 0.944, neutral: 0.034})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_analyzer.predict(\"Oh meu Deus!\") # Em Ingl√™s e: \"omg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=[], probas={admiration: 0.095, amusement: 0.261, anger: 0.016, annoyance: 0.016, approval: 0.005, caring: 0.001, confusion: 0.001, curiosity: 0.001, desire: 0.001, disappointment: 0.003, disapproval: 0.001, disgust: 0.001, embarrassment: 0.002, excitement: 0.089, fear: 0.000, gratitude: 0.003, grief: 0.001, joy: 0.168, love: 0.001, nervousness: 0.000, optimism: 0.001, pride: 0.006, realization: 0.014, relief: 0.004, remorse: 0.001, sadness: 0.001, surprise: 0.035, neutral: 0.231})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_2 = emotion_analyzer.predict(\"Gol do Brasil!\")\n",
    "\n",
    "emotion_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admiration': 0.09488872438669205,\n",
       " 'amusement': 0.2614235281944275,\n",
       " 'anger': 0.016178186982870102,\n",
       " 'annoyance': 0.016428008675575256,\n",
       " 'approval': 0.0045191398821771145,\n",
       " 'caring': 0.0008352831937372684,\n",
       " 'confusion': 0.000655831303447485,\n",
       " 'curiosity': 0.000696275441441685,\n",
       " 'desire': 0.0006572880083695054,\n",
       " 'disappointment': 0.0025380225852131844,\n",
       " 'disapproval': 0.0011165443575009704,\n",
       " 'disgust': 0.0011116702808067203,\n",
       " 'embarrassment': 0.0018576275324448943,\n",
       " 'excitement': 0.08896475285291672,\n",
       " 'fear': 0.00023081747349351645,\n",
       " 'gratitude': 0.00258094840683043,\n",
       " 'grief': 0.001126772491261363,\n",
       " 'joy': 0.16801756620407104,\n",
       " 'love': 0.0005174428806640208,\n",
       " 'nervousness': 0.00028827451751567423,\n",
       " 'optimism': 0.0006350059993565083,\n",
       " 'pride': 0.006065180525183678,\n",
       " 'realization': 0.014104055240750313,\n",
       " 'relief': 0.004411832429468632,\n",
       " 'remorse': 0.001243908074684441,\n",
       " 'sadness': 0.0012675581965595484,\n",
       " 'surprise': 0.034669265151023865,\n",
       " 'neutral': 0.23090434074401855}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_2.probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Emo√ß√£o da nossa senten√ßa √©: amusement com uma probabilidade de: 0.2614235281944275\n"
     ]
    }
   ],
   "source": [
    "name_of_emotion  = max(emotion_2.probas, key=emotion_2.probas.get)\n",
    "\n",
    "value_of_emotion = emotion_2.probas[name_of_emotion]\n",
    "\n",
    "print(f\"A Emo√ß√£o da nossa senten√ßa √©: {name_of_emotion} com uma probabilidade de: {value_of_emotion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=['nervousness'], probas={admiration: 0.002, amusement: 0.002, anger: 0.005, annoyance: 0.013, approval: 0.007, caring: 0.195, confusion: 0.011, curiosity: 0.019, desire: 0.006, disappointment: 0.022, disapproval: 0.004, disgust: 0.004, embarrassment: 0.005, excitement: 0.012, fear: 0.335, gratitude: 0.006, grief: 0.009, joy: 0.008, love: 0.008, nervousness: 0.630, optimism: 0.006, pride: 0.004, realization: 0.018, relief: 0.010, remorse: 0.002, sadness: 0.115, surprise: 0.002, neutral: 0.033})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_analyzer.predict(\"As pessoas no mundo est√£o realmente preocupadas por causa do Coronav√≠rus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"yellow\">Discurso de √≥dio (`Hate Speech`)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pysentimiento` tamb√©m oferece suporte √† detec√ß√£o de `discurso de √≥dio`, treinando modelos usando o conjunto de dados [HatEval](https://competitions.codalab.org/competitions/19935)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (‚Ä¶)lve/main/config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 936/936 [00:00<00:00, 1.38MB/s]\n",
      "Downloading pytorch_model.bin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 541M/541M [02:23<00:00, 3.76MB/s] \n",
      "Downloading (‚Ä¶)okenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 418/418 [00:00<00:00, 549kB/s]\n",
      "Downloading (‚Ä¶)solve/main/vocab.txt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 504k/504k [00:00<00:00, 2.45MB/s]\n",
      "Downloading (‚Ä¶)/main/tokenizer.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.52M/1.52M [00:01<00:00, 1.14MB/s]\n",
      "Downloading (‚Ä¶)in/added_tokens.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41.0/41.0 [00:00<00:00, 51.6kB/s]\n",
      "Downloading (‚Ä¶)cial_tokens_map.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:00<00:00, 129kB/s]\n"
     ]
    }
   ],
   "source": [
    "hate_speech_analyzer = create_analyzer(task=\"hate_speech\", lang='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Este modelo √© um algoritmo de `classifica√ß√£o multir√≥tulo``, retornando tr√™s vari√°veis ‚Äã‚Äãdiferentes ao mesmo tempo:\n",
    "\n",
    "* A mensagem √© odiosa (`hateful`) ou n√£o?\n",
    "\n",
    "* A mensagem de odiosa √© dirigida (`targeted`) a uma pessoa ou grupo espec√≠fico?\n",
    "\n",
    "* A mensagem odiosa √© agressiva (`aggressive`)?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=['Sexism', 'Body'], probas={Sexism: 0.777, Body: 0.705, Racism: 0.090, Ideology: 0.055, Homophobia: 0.010})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_1 = hate_speech_analyzer.predict(\"Odeio a todos os gordos\")\n",
    "\n",
    "hate_speech_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sexism', 'Body']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_1.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sexism': 0.7774370312690735,\n",
       " 'Body': 0.7049675583839417,\n",
       " 'Racism': 0.09032890200614929,\n",
       " 'Ideology': 0.05541188269853592,\n",
       " 'Homophobia': 0.010256546549499035}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_1.probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=[], probas={Sexism: 0.004, Body: 0.002, Racism: 0.004, Ideology: 0.003, Homophobia: 0.003})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_analyzer.predict(\"Todos esses imigrantes devem ser aniquilados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=[], probas={Sexism: 0.005, Body: 0.002, Racism: 0.011, Ideology: 0.003, Homophobia: 0.003})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_analyzer.predict(\"O Hitler foi uma desgra√ßa de ser humano.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=['Homophobia'], probas={Sexism: 0.039, Body: 0.008, Racism: 0.021, Ideology: 0.014, Homophobia: 0.960})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_analyzer.predict(\"Chega de homossexuais, gays e outros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=['Ideology'], probas={Sexism: 0.059, Body: 0.018, Racism: 0.051, Ideology: 0.805, Homophobia: 0.046})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_analyzer.predict(\"Todos os comunistas s√£o terroristas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"yellow\">Tarefas de rotulagem de Token (`Token Labeling tasks`)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pysentimiento` tamb√©m possui tags `POS` e analisadores `NER`, especialmente criados para dados do `Twitter`, gra√ßas ao conjunto de dados [LinCE](https://ritual.uh.edu/lince/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">NER</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (‚Ä¶)lve/main/config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.48k/1.48k [00:00<00:00, 2.30MB/s]\n",
      "Downloading pytorch_model.bin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 433M/433M [01:54<00:00, 3.79MB/s] \n",
      "Downloading (‚Ä¶)okenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 334/334 [00:00<00:00, 299kB/s]\n",
      "Downloading (‚Ä¶)/main/tokenizer.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 858k/858k [00:00<00:00, 3.71MB/s]\n",
      "Downloading (‚Ä¶)cial_tokens_map.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:00<00:00, 220kB/s]\n"
     ]
    }
   ],
   "source": [
    "# NOTA: NER & POS tagging s√≥ para Espahol e Ingl√©s:\n",
    "\n",
    "ner_analyzer = create_analyzer(\"ner\", lang='es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenClassificationOutput(entities=[Per√∫ (LOC)], tokens=['Me', 'voy', 'de', 'vacaciones', 'a', 'Per√∫', ' ', 'emoji', 'cara', 'sonriendo', 'con', 'gafas', 'de', 'sol', 'emoji'], labels=['O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_analyzer.predict(\"Me voy de vacaciones a Per√∫ üòé\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenClassificationOutput(entities=[Juan Manuel P√©rez (PER), bandera (LOC), argentina (LOC)], tokens=['Me', 'llamo', 'Juan', 'Manuel', 'P√©rez', 'y', 'vivo', 'en', ' ', 'emoji', 'bandera', 'argentina', 'emoji', ' ', 'emoji', 'cara', 'sonriendo', 'con', 'gafas', 'de', 'sol', 'emoji'], labels=['O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_analyzer.predict(\"Me llamo Juan Manuel P√©rez y vivo en üá¶üá∑üòé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Part-Of-Speech (`POS`)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essas `tags POS(Partes do discurso)`, s√£o r√≥tulos atribu√≠dos a cada palavra em um texto para indicar a fun√ß√£o gramatical daquela palavra em uma senten√ßa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 433M/433M [02:29<00:00, 2.90MB/s]\n",
      "Downloading (‚Ä¶)okenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 330/330 [00:00<00:00, 484kB/s]\n",
      "Downloading (‚Ä¶)/main/tokenizer.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 829k/829k [00:00<00:00, 1.66MB/s]\n",
      "Downloading (‚Ä¶)cial_tokens_map.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:00<00:00, 102kB/s]\n"
     ]
    }
   ],
   "source": [
    "pos_tagger = create_analyzer(\"pos\", \"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenClassificationOutput(tokens=['Me', 'llamo', 'Karina', 'Gon√ßalves', 'y', 'soy', 'cientista', 'de', 'Datos', 'y', 'vivo', 'en', 'Brasil', '.'], labels=['PRON', 'VERB', 'PROPN', 'PROPN', 'CONJ', 'VERB', 'NOUN', 'ADP', 'PROPN', 'CONJ', 'VERB', 'ADP', 'PROPN', 'PUNCT'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagger_1 =  pos_tagger.predict(\"Me llamo Karina Gon√ßalves y soy cientista de Datos y vivo en Brasil.\")\n",
    "\n",
    "pos_tagger_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Me',\n",
       " 'llamo',\n",
       " 'Karina',\n",
       " 'Gon√ßalves',\n",
       " 'y',\n",
       " 'soy',\n",
       " 'cientista',\n",
       " 'de',\n",
       " 'Datos',\n",
       " 'y',\n",
       " 'vivo',\n",
       " 'en',\n",
       " 'Brasil',\n",
       " '.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagger_1.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON',\n",
       " 'VERB',\n",
       " 'PROPN',\n",
       " 'PROPN',\n",
       " 'CONJ',\n",
       " 'VERB',\n",
       " 'NOUN',\n",
       " 'ADP',\n",
       " 'PROPN',\n",
       " 'CONJ',\n",
       " 'VERB',\n",
       " 'ADP',\n",
       " 'PROPN',\n",
       " 'PUNCT']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagger_1.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"yellow\">Pr√©-processando (`Preprocessing`)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`pysentimiento` apresenta um m√≥dulo de pr√©-processamento com v√°rias op√ß√µes para manipula√ß√£o de `hashtags`, `emojis`, `repeti√ß√£o de caracteres` e assim por diante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"emoji buzina emoji  O Twitter removeu as postagens de @USER por 'violar as regras de conviv√™ncia' hashtag breaking news\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "\n",
    "preprocess_tweet(\"üì¢ O Twitter removeu as postagens de @JairBolsonaro por 'violar as regras de conviv√™ncia' #BreakingNews\",\n",
    "                 lang=\"pt\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"üì¢ O Twitter removeu as postagens de @JairBolsonaro por 'violar as regras de conviv√™ncia' #BreakingNews\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_tweet(\"üì¢ O Twitter removeu as postagens de @JairBolsonaro por 'violar as regras de conviv√™ncia' #BreakingNews\",\n",
    "                 preprocess_handles=False,\n",
    "                 demoji=False,\n",
    "                 preprocess_hashtags=False\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pysent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
